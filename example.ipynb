{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.model import get_model\n",
    "from scripts.attribution_methods import generate_attributions\n",
    "from captum.attr import visualization as viz\n",
    "from scripts.normalize import normalize\n",
    "import scripts.datasets as datasets\n",
    "from scripts.ensemble import generate_ensembles\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"model\": \"Resnet18_cifar10\",\n",
    "    \"dataset\": \"cifar10\",\n",
    "    \"batch_size\": 20,\n",
    "    \"max_nr_batches\": 50,  # -1 for no early stopping\n",
    "    \"attribution_methods\": [\n",
    "        \"gradientshap\",\n",
    "        \"deeplift\",\n",
    "        \"lime\",\n",
    "        \"saliency\",\n",
    "        \"smoothgrad\",\n",
    "        \"integrated_gradients\",\n",
    "        \"guidedbackprop\",\n",
    "        \"gray_image\",\n",
    "    ],\n",
    "    \"ensemble_methods\": [\n",
    "        \"mean\",\n",
    "        \"variance\",\n",
    "        \"rbm\",\n",
    "        \"flipped_rbm\",\n",
    "        \"rbm_flip_detection\",\n",
    "    ],\n",
    "    \"attribution_processing\": \"filtering\",\n",
    "    \"normalization\": \"min_max\",\n",
    "    \"scoring_methods\": [\"insert\", \"delete\", \"irof\"],\n",
    "    \"scores_batch_size\": 40,\n",
    "    \"package_size\": 1,\n",
    "    \"irof_segments\": 60,\n",
    "    \"irof_sigma\": 4,\n",
    "    \"batches_to_plot\": [],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "attribution_params = {\n",
    "    \"lime\": {\n",
    "        \"use_slic\": True,\n",
    "        \"n_slic_segments\": 100,\n",
    "    },\n",
    "    \"integrated_gradients\": {\n",
    "        \"baseline\": \"black\",\n",
    "    },\n",
    "    \"noise_normal\": {},\n",
    "    \"deeplift\": {},\n",
    "    \"gradientshap\": {},\n",
    "    \"saliency\": {},\n",
    "    \"occlusion\": {},\n",
    "    \"smoothgrad\": {},\n",
    "    \"guidedbackprop\": {},\n",
    "    \"gray_image\": {},\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "rbm_params = {\n",
    "    \"batch_size\": 15,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"n_iter\": 300,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def plot(images, raw_images, attributions, ensemble_attributions, plot_text=\"\"):\n",
    "    for idx in range(len(images)):\n",
    "        # idx = 0  # first image of the batch\n",
    "        orig_image = raw_images[idx].detach().cpu().numpy()\n",
    "        orig_image = orig_image.transpose(1, 2, 0)\n",
    "        # For MNIST remove the color dimension\n",
    "        if orig_image.shape[2] == 1:\n",
    "            orig_image = orig_image.reshape(orig_image.shape[0:2])\n",
    "        images = [orig_image]\n",
    "\n",
    "        # one image for every attribution method\n",
    "        for j, title in enumerate(params[\"attribution_methods\"]):\n",
    "            # Remove randoms step 1\n",
    "            if \"noise\" in title:\n",
    "                continue\n",
    "            attribution_img = attributions[j][idx].cpu().detach().numpy()\n",
    "            images.append(attribution_img)\n",
    "            #     # one image for every ensemble method\n",
    "        for j in range(len(params[\"ensemble_methods\"])):\n",
    "            ensemble_img = ensemble_attributions[j][idx].cpu().detach().numpy()\n",
    "            images.append(ensemble_img)\n",
    "\n",
    "        # Remove the randoms step 2\n",
    "        non_random = np.array([\"noise\" not in t for t in params[\"attribution_methods\"]])\n",
    "        attr_methods = np.array(params[\"attribution_methods\"])[non_random]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def my_plot(images, titles, main_title=\"\"):\n",
    "    # make a square\n",
    "    x = int(np.ceil(np.sqrt(len(images))))\n",
    "    fig, axs = plt.subplots(x, x, figsize=(30, 40))\n",
    "    fig.suptitle(main_title)\n",
    "\n",
    "    # Remove the NaNs\n",
    "    for i in range(len(images)):\n",
    "        images[i][np.isnan(images[i])] = 0\n",
    "\n",
    "    # Ensure that all attributions get equal weight during plotting\n",
    "    mean_max_value = np.mean([np.max(img / np.sum(img)) for img in images[1:]])\n",
    "\n",
    "    # plot the images\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if i < len(images):\n",
    "            if i == 0:\n",
    "                # Show the original image\n",
    "                ax.imshow(images[i])\n",
    "            else:\n",
    "                # Plot the attributions and ensure equal plotting\n",
    "                img = images[i] / np.sum(images[i]) / mean_max_value\n",
    "                ax.imshow(img, vmin=0, vmax=1 / 3, cmap=\"Greens\")\n",
    "            ax.set_axis_off()\n",
    "            ax.set_title(titles[i])\n",
    "        else:\n",
    "            ax.set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## running the code"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# classification model\n",
    "model = get_model(params[\"model\"], device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# dataset and which images to explain the classification for\n",
    "dataset = datasets.get_dataset(params[\"dataset\"])\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=1, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "img, label = next(iter(dataloader))\n",
    "img = img.to(device)\n",
    "label = label.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "###########################\n",
    "#      attributions       #\n",
    "###########################\n",
    "attributions = generate_attributions(\n",
    "    img,\n",
    "    label,\n",
    "    model,\n",
    "    params,\n",
    "    attribution_params,\n",
    "    device,\n",
    ")\n",
    "\n",
    "zero = torch.Tensor([0]).to(device)\n",
    "# Set negative values to zero\n",
    "attributions = torch.max(attributions, zero)\n",
    "# Make sure we have values in range [0,1]\n",
    "attributions = normalize(params[\"normalization\"], arr=attributions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "###########################\n",
    "#        ensembles        #\n",
    "###########################\n",
    "\n",
    "ensemble_attributions = generate_ensembles(\n",
    "    attributions, params[\"ensemble_methods\"], rbm_params, device\n",
    ")\n",
    "\n",
    "# make sure it sums to 1\n",
    "ensemble_attributions = normalize(\n",
    "    params[\"normalization\"], arr=ensemble_attributions\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}