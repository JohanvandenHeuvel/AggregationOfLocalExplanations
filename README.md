# A Robust Unsupervised Ensemble of Feature-Based Explanations using Restricted Boltzmann Machines

Understanding the results of deep neural networks is an essential step towards wider acceptance of deep learning algorithms. Many approaches address the issue of interpreting artificial neural networks, but often provide divergent explanations. Moreover, different hyperparameters of an explanatory method can lead to conflicting interpretations. 
In this paper, we propose a technique for aggregating the feature attributions of different explanatory algorithms using a Restricted Boltzmann machine (RBM) to achieve a more accurate and robust interpretation of deep neural networks. 
Several challenging experiments on real-world datasets show that the proposed RBM method outperforms popular feature attribution methods and basic ensemble techniques. 

In the figure below visual results for our RBM method is shown (last column).

![visual results](https://github.com/JohanvandenHeuvel/AggregationOfLocalExplanations/blob/main/plot.png?raw=true)
